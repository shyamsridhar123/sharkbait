# Context and token management

| Field | Value |
|-------|-------|
| ID | SB-004.02 |
| Parent | SB-004 |
| Status | Completed |
| Priority | high |
| Created | 2025-01-13 |
| Updated | 2026-01-28 |

## Description

Intelligent context management with **compaction strategies** for 128K token limit:

**Context Classification:**
- **Preserved (NEVER compact):** System prompt, TaskLedger, last 10 messages, active files, error context
- **Compactable:** Older messages, tool results, exploration findings

**Compaction Strategies (applied in order):**
1. Summarize old tool results (keep last 5 full)
2. LLM-generated conversation summary for older messages
3. Move exploration key facts to TaskLedger, summarize rest

**Token Management:**
- Token counting with tiktoken or approximation
- Compaction threshold: 85% of max tokens
- Reserved for response: 16K tokens

## Acceptance Criteria

- [ ] Accurate token counting
- [ ] **ContextManager class with preserved/compactable separation**
- [ ] **Compaction triggers at 85% threshold**
- [ ] **Tool result summarization (keep last 5 full)**
- [ ] **LLM-powered conversation history summarization**
- [ ] **Exploration findings â†’ TaskLedger migration**
- [ ] Large file chunking strategy
- [ ] Context overflow prevention
- [ ] Integration with agent loop

## References

- TRD Section 3.3: Context Management
